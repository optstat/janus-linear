{
    "sourceFile": "src/cpp/qr.hpp",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1718917043003,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1718917043003,
            "name": "Commit-0",
            "content": "#ifndef QR_HPP_INCLUDED\n#define QR_HPP_INCLUDED\n// def signcond(a, b):\n//     return torch.where(b >= 0, torch.where(a >= 0, a, -a), torch.where(a >= 0, -a, a))\n\n#include <torch/torch.h>\n#include \"janus/janus_util.hpp\"\n\n\nusing Slice = torch::indexing::Slice;\n\nnamespace janus\n{\n\n\n\n    class QR\n    {\n    public:\n        int n, m;\n        bool isComplex = false;\n        bool sing = false;\n        torch::Tensor a, r, qt, c, d;\n        torch::Tensor scale, sm, tau, sigma, zero, Rkek, Qt_b, x;\n        torch::Tensor qt_real, qt_imag, c_real, c_imag, d_real, d_imag;\n\n        QR(const torch::Tensor &a)\n        {\n            if ( a.isreal().all().item<bool>() ) {\n                if (a.isnan().any().item<bool>() || a.isinf().any().item<bool>())\n                {\n                    std::cerr << \"a=\" << a << std::endl;\n                    throw std::runtime_error(\"a has nan or inf\");\n                }\n            }\n            if ( a.is_complex() ) {\n                if (at::real(a).isnan().any().item<bool>() || at::real(a).isinf().any().item<bool>()\n                    || at::imag(a).isnan().any().item<bool>() || at::imag(a).isinf().any().item<bool>())\n                {\n                    std::cerr << \"a=\" << a << std::endl;\n                    throw std::runtime_error(\"a has nan or inf\");\n                }\n            }\n\n            this->a = a.clone(); // copy of the original matrix\n            // check to see if a is complex\n            if (a.is_complex())\n            {\n                isComplex = true;\n                zero = torch::complex(torch::zeros({1}, torch::TensorOptions().dtype(torch::kDouble).device(a.device())), \n                                      torch::zeros({1}, torch::TensorOptions().dtype(torch::kDouble).device(a.device())));\n                \n            }\n            else {\n                zero = torch::zeros({1}, torch::TensorOptions().dtype(torch::kDouble).device(a.device()));\n            }\n            n = a.size(0);\n            assert(a.size(0) == a.size(1));\n            r = a.clone();\n            std::cerr << \"r=\";\n            print_matrix(r);\n            //Print the dimensions of r\n            std::cerr << \"r.size(0)=\" << r.size(0) << std::endl;\n            std::cerr << \"r.size(1)=\" << r.size(1) << std::endl;\n            //check for nan or inf in a\n            if (!isComplex)\n            {\n                qt = torch::zeros({n, n}, torch::TensorOptions().dtype(a.dtype()).device(a.device()));\n                c = torch::zeros({n}, torch::TensorOptions().dtype(a.dtype()).device(a.device()));\n                d = torch::zeros({n}, torch::TensorOptions().dtype(a.dtype()).device(a.device()));\n            }\n            else\n            {\n                qt_real = torch::zeros({n, n}, torch::kDouble).to(a.device());\n                qt_imag = torch::zeros({n, n}, torch::kDouble).to(a.device());\n                qt = torch::complex(qt_real, qt_imag).to(torch::kComplexDouble);\n                c_real = torch::zeros({n}, torch::kDouble).to(a.device());\n                c_imag = torch::zeros({n}, torch::kDouble).to(a.device());\n                c = torch::complex(c_real, c_imag).to(torch::kComplexDouble);\n                d_real = torch::zeros({n}, torch::kDouble).to(a.device());\n                d_imag = torch::zeros({n}, torch::kDouble).to(a.device());\n                d = torch::complex(d_real, d_imag).to(torch::kComplexDouble);\n            }\n            for (int k = 0; k < n - 1; k++)\n            {\n                scale = zero;\n                Rkek = r.index({Slice(k), k});\n                std::cerr << \"Rkek=\";\n                print_vector(Rkek);\n                //scale = max(abs(Rkek));\n                auto res = torch::max(Rkek.abs(), 0);\n                scale = std::get<0>(res);\n                std::cerr << \"scale=\" << scale << std::endl;\n                \n                auto scaled_r = r.index({Slice(k), k}) / scale;\n                r.index_put_({Slice(k), k}, scaled_r);\n                //for (sum=0.0,i=k;i<n;i++) sum += SQR(r[i][k]);\n                sm = torch::sum(r.index({Slice(k), k}).square());\n                //sigma=SIGN(sqrt(sum),r[k][k]);\n                torch::Tensor sqrtsm = torch::sqrt(sm);\n                torch::Tensor rkk = r.index({k, k});\n                sigma = janus::signcond(sqrtsm, rkk);\n                std::cerr << \"sigma=\" << sigma << std::endl;\n                std::cerr << \"r before index put=\";\n                print_matrix(r);\n                r.index_put_({k, k}, r.index({k, k}) + sigma);\n                std::cerr << \"r after index put=\";\n                print_matrix(r);\n                c.index_put_({k}, sigma * r.index({k, k}));\n                assert ((c.index({k}).abs() > 0).item<bool>());\n                //d[k] = -scale*sigma;\n                d.index_put_({k}, -scale * sigma);\n                std::cerr << \"c=\";\n                print_vector(c);\n                std::cerr << \"d=\";\n                print_vector(d);\n\n                for (int j = k + 1; j < n; j++)\n                {\n                    sm = torch::sum(r.index({Slice(k), k}) * r.index({Slice(k), j}));\n                    tau = sm / c.index({k});\n                    std::cerr << \"c at k=\" << k << \" =\" << c.index({k}) << std::endl;\n                    std::cerr << \"tau at k=\" << k << \" =\" << tau << std::endl;\n                    if (torch::isnan(tau).any().item<bool>() || torch::isinf(tau).any().item<bool>()) {\n                        std::cerr << \"tau=\" << tau << std::endl;\n                        throw std::runtime_error(\"tau has nan or inf\");\n                    }\n                    auto ratj = r.index({Slice(k), j});\n                    auto ratk = r.index({Slice(k), k});\n                    r.index_put_({Slice(k), j}, ratj - tau * ratk);\n                }\n                std::cerr << \"r=\";\n                print_matrix(r);\n            } // for k\n\n            if (!isComplex)\n            {\n                d[n - 1] = r[n - 1][n - 1];\n            }\n            else\n            {\n                // Extract real and imaginary parts of r\n                auto r_real = at::real(r);\n                auto r_imag = at::imag(r);\n\n                // Extract real and imaginary parts of d\n                auto d_real = at::real(d);\n                auto d_imag = at::imag(d);\n                // Update the real and imaginary parts separately\n                d_real.index_put_({n - 1}, r_real.index({n - 1, n - 1}));\n                d_imag.index_put_({n - 1}, r_imag.index({n - 1, n - 1}));\n\n                // Recombine the updated real and imaginary parts\n                d = at::complex(d_real, d_imag);\n\n            }\n            std::cerr << \"d=\";\n            print_vector(d);\n\n            if (!isComplex)\n            {\n                qt = torch::eye(n, torch::TensorOptions().dtype(a.dtype()).device(a.device()));\n            }\n            else\n            {\n                qt_real = torch::eye(n, torch::kDouble).to(a.device());\n                qt_imag = torch::zeros({n, n}, torch::kDouble).to(a.device());\n                qt = torch::complex(qt_real, qt_imag);\n            }\n            for (int k = 0; k < n - 1; k++)\n            {\n                torch::Tensor catk;\n                if ( isComplex) \n                   catk = at::real(c.index({k}));\n                else \n                   catk = c.index({k});\n                if ((catk != 0.0).item<bool>())\n                {\n                    torch::Tensor sm;\n                    for (int j = 0; j < n; j++)\n                    {\n                      sm = torch::sum(r.index({Slice(k), k}) * qt.index({Slice(k), j})); \n                    \n                      sm = sm / c.index({k});\n                      qt.index_put_({Slice(k), j}, qt.index({Slice(k), j}) - sm * r.index({Slice(k), k}));\n                    }\n                }\n            }\n            std::cerr << \"qt=\";\n            print_matrix(qt);\n            for (int i=0;i<n;i++) {\n\t\t      //r[i][i]=d[i];\n              r.index_put_({i, i}, d[i]);\n              r.index_put_({i, Slice(0, i)}, zero);\n            }\n            std::cerr << \"r=\";\n            print_matrix(r);\n\n            if ( !isComplex ) {\n                //check for nan or inf in qt\n                if (qt.isnan().any().item<bool>() || qt.isinf().any().item<bool>())\n                {\n                    std::cerr << \"qt=\" << qt << std::endl;\n                    throw std::runtime_error(\"qt has nan or inf\");\n                }\n                //check for nan or inf in r\n                if (r.isnan().any().item<bool>() || r.isinf().any().item<bool>())\n                {\n                    std::cerr << \"r=\" << r << std::endl;\n                    throw std::runtime_error(\"r has nan or inf\");\n                }\n\n            } \n        } // QR constructor\n\n        torch::Tensor solvev(torch::Tensor &bin)\n        {\n            // qtx = self.qt*b\n            //In this formulation the Q matrix is already transposed\n            std::cerr << \"qt=\" << qt << std::endl;\n            std::cerr << \"bin=\" << bin << std::endl;\n            Qt_b = torch::einsum(\"ij,j->i\", {qt, bin});\n            //We need to solve for R*x = QT*b backwards\n            x = torch::zeros_like(Qt_b);\n            for (int i=n-1;i>-1; i--) {\n              x[i] = Qt_b[i];\n              auto sm = torch::sum(r.index({i, Slice(i+1, n)}) * x.index({Slice(i+1, n)}));\n              x[i] = x[i]-sm;\n\n\n              x[i] = x[i] / r[i][i];\n            }\n            return x.clone();\n        }\n\n    }; // class QR\n};     // namespace janust\n#endif // QR_HPP_INCLUDED"
        }
    ]
}